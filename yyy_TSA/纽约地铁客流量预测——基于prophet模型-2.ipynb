{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af16050-ac42-4fca-bdcb-39503b449650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Collecting prophet\n",
      "  Using cached prophet-1.1.6-py3-none-macosx_10_11_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Collecting holidays\n",
      "  Downloading holidays-0.72-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Collecting cmdstanpy>=1.0.4 (from prophet)\n",
      "  Downloading cmdstanpy-1.2.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/anaconda3/lib/python3.12/site-packages (from prophet) (4.66.5)\n",
      "Collecting importlib-resources (from prophet)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting stanio<2.0.0,>=0.4.0 (from cmdstanpy>=1.0.4->prophet)\n",
      "  Downloading stanio-0.5.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading prophet-1.1.6-py3-none-macosx_10_11_x86_64.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading holidays-0.72-py3-none-any.whl (932 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.3/932.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cmdstanpy-1.2.5-py3-none-any.whl (94 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading stanio-0.5.1-py3-none-any.whl (8.1 kB)\n",
      "Installing collected packages: stanio, importlib-resources, holidays, cmdstanpy, prophet\n",
      "Successfully installed cmdstanpy-1.2.5 holidays-0.72 importlib-resources-6.5.2 prophet-1.1.6 stanio-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy matplotlib seaborn prophet scikit-learn holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3dcdd0-395e-49df-8d11-a83be8a9e094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载2014年数据: 10810000行, 11列\n",
      "成功加载2015年数据: 9950000行, 11列\n",
      "成功加载2016年数据: 9492670行, 11列\n",
      "成功加载2017年数据: 8880000行, 11列\n",
      "成功加载2018年数据: 10111471行, 11列\n",
      "合并后数据总量: 49244141行, 11列\n",
      "Index(['C/A', 'Unit', 'SCP', 'Station', 'Line Name', 'Division', 'Date', 'Time', 'Description', 'Entries', 'Exits                                                     '], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = load_turnstile_data()\n",
    "print(df.columns)  # 查看所有列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214d57c4-3b8d-4bcd-a38d-e262aa3ac4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始执行地铁客流量分析与预测...\n",
      "成功加载2014年数据: 10810000行, 11列\n",
      "成功加载2015年数据: 9950000行, 11列\n",
      "成功加载2016年数据: 9492670行, 11列\n",
      "成功加载2017年数据: 8880000行, 11列\n",
      "成功加载2018年数据: 10111471行, 11列\n",
      "合并后数据总量: 49244141行, 11列\n",
      "开始数据预处理...\n",
      "修正后的列名: ['C/A', 'Unit', 'SCP', 'Station', 'Line Name', 'Division', 'Date', 'Time', 'Description', 'Entries', 'Exits']\n",
      "计算客流量增量...\n",
      "预处理后数据量: 49236835行\n",
      "聚合数据到D频率...\n",
      "聚合后数据量: 486811行\n",
      "分析站点客流量...\n",
      "客流量最高的10个站点:\n",
      "             Station  TOTAL_TRAFFIC  ENTRIES_DIFF   EXITS_DIFF\n",
      "86    34 ST-PENN STA    340979966.0   181900317.0  159079649.0\n",
      "21    14 ST-UNION SQ    264382991.0   141172443.0  123210548.0\n",
      "84   34 ST-HERALD SQ    263445675.0   134087855.0  129357820.0\n",
      "258         CANAL ST    181485176.0   101261720.0   80223456.0\n",
      "64             23 ST    173562882.0   100211670.0   73351212.0\n",
      "340        FULTON ST    171098318.0    95685852.0   75412466.0\n",
      "160            86 ST    152828326.0    82951599.0   69876727.0\n",
      "12            125 ST    145275667.0    79445954.0   65829713.0\n",
      "268      CHAMBERS ST    127390072.0    74959964.0   52430108.0\n",
      "98    42 ST-TIMES SQ    118659960.0    61498487.0   57161473.0\n",
      "准备时间序列数据...\n",
      "时间序列数据范围: 2014-02-01 00:00:00 到 2018-12-28 00:00:00\n",
      "添加假日信息...\n",
      "假日数据预览:\n",
      "          ds           holiday  lower_window  upper_window\n",
      "0 2016-01-01    New Year's Day            -2             2\n",
      "1 2016-05-30      Memorial Day            -1             1\n",
      "2 2016-07-04  Independence Day            -2             2\n",
      "3 2016-09-05         Labor Day            -1             1\n",
      "4 2016-11-11      Veterans Day            -1             1\n",
      "假日数据列名: ['ds', 'holiday', 'lower_window', 'upper_window']\n",
      "训练Prophet模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:15:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型训练完成，预测未来90天\n",
      "预测结果列: ['ds', 'trend', 'yhat_lower', 'yhat_upper', 'trend_lower', 'trend_upper', 'Christmas Day', 'Christmas Day_lower', 'Christmas Day_upper', 'Christmas Day (observed)', 'Christmas Day (observed)_lower', 'Christmas Day (observed)_upper', 'Columbus Day', 'Columbus Day_lower', 'Columbus Day_upper', 'Independence Day', 'Independence Day_lower', 'Independence Day_upper', 'Independence Day (observed)', 'Independence Day (observed)_lower', 'Independence Day (observed)_upper', 'Labor Day', 'Labor Day_lower', 'Labor Day_upper', 'Martin Luther King Jr. Day', 'Martin Luther King Jr. Day_lower', 'Martin Luther King Jr. Day_upper', 'Memorial Day', 'Memorial Day_lower', 'Memorial Day_upper', \"New Year's Day\", \"New Year's Day_lower\", \"New Year's Day_upper\", \"New Year's Day (observed)\", \"New Year's Day (observed)_lower\", \"New Year's Day (observed)_upper\", 'Thanksgiving Day', 'Thanksgiving Day_lower', 'Thanksgiving Day_upper', 'Veterans Day', 'Veterans Day_lower', 'Veterans Day_upper', 'Veterans Day (observed)', 'Veterans Day (observed)_lower', 'Veterans Day (observed)_upper', \"Washington's Birthday\", \"Washington's Birthday_lower\", \"Washington's Birthday_upper\", 'daily', 'daily_lower', 'daily_upper', 'holidays', 'holidays_lower', 'holidays_upper', 'monthly', 'monthly_lower', 'monthly_upper', 'multiplicative_terms', 'multiplicative_terms_lower', 'multiplicative_terms_upper', 'quarterly', 'quarterly_lower', 'quarterly_upper', 'weekly', 'weekly_lower', 'weekly_upper', 'yearly', 'yearly_lower', 'yearly_upper', 'additive_terms', 'additive_terms_lower', 'additive_terms_upper', 'yhat']\n",
      "可视化预测结果...\n",
      "已生成交互式HTML可视化\n",
      "分析假日效应...\n",
      "找到的假日效应列: ['Christmas Day', 'Christmas Day_lower', 'Christmas Day_upper', 'Christmas Day (observed)', 'Christmas Day (observed)_lower', 'Christmas Day (observed)_upper', 'Independence Day', 'Independence Day_lower', 'Independence Day_upper', 'Independence Day (observed)', 'Independence Day (observed)_lower', 'Independence Day (observed)_upper', \"New Year's Day\", \"New Year's Day_lower\", \"New Year's Day_upper\", \"New Year's Day (observed)\", \"New Year's Day (observed)_lower\", \"New Year's Day (observed)_upper\", 'Thanksgiving Day', 'Thanksgiving Day_lower', 'Thanksgiving Day_upper', 'holidays', 'holidays_lower', 'holidays_upper']\n",
      "假日效应最显著的10个日期:\n",
      "             ds  holiday_effect  abs_effect\n",
      "1015 2016-12-31      -16.987806   16.987806\n",
      "1630 2018-11-10       -9.621180    9.621180\n",
      "971  2016-11-10       -9.621180    9.621180\n",
      "282  2014-11-10       -9.621180    9.621180\n",
      "1007 2016-12-23       -8.109600    8.109600\n",
      "1330 2017-12-23       -8.109600    8.109600\n",
      "669  2015-12-23       -8.109600    8.109600\n",
      "325  2014-12-23       -8.109600    8.109600\n",
      "1673 2018-12-23       -8.109600    8.109600\n",
      "299  2014-11-27        6.144360    6.144360\n",
      "评估模型性能...\n",
      "平均绝对误差 (MAE): 1232848.10\n",
      "均方根误差 (RMSE): 2950125.65\n",
      "平均绝对百分比误差 (MAPE): 22.82%\n",
      "95%置信区间覆盖率: 96.90%\n",
      "\n",
      "分析完成! 已生成多个可视化图表。\n",
      "预测结果已保存到 'prophet_forecast_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import holidays\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False    # 用来正常显示负号\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"开始执行地铁客流量分析与预测...\")\n",
    "\n",
    "def load_turnstile_data(years=None):\n",
    "    \"\"\"\n",
    "    加载多年的闸机数据\n",
    "    \n",
    "    参数:\n",
    "    years (list): 需要加载的年份列表，默认为所有可用数据(2014-2018)\n",
    "    \n",
    "    返回:\n",
    "    DataFrame: 合并后的数据框\n",
    "    \"\"\"\n",
    "    if years is None:\n",
    "        years = ['2014', '2015', '2016', '2017', '2018']\n",
    "    \n",
    "    all_data = []\n",
    "    desktop_path = os.path.join(os.path.expanduser('~'),'Desktop')\n",
    "\n",
    "    for year in years:\n",
    "        file_name = f'turnstile-usage-data-{year}.csv'\n",
    "        file_path = os.path.join(desktop_path, file_name)\n",
    "        \n",
    "        if os.path.exists(f'{file_path}.csv'):\n",
    "            df = pd.read_csv(f'{file_path}.csv')\n",
    "        elif os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif os.path.exists(f'{file_path}.txt'):\n",
    "            df = pd.read_csv(f'{file_path}.txt')\n",
    "        else:\n",
    "            print(f\"警告: 找不到{year}年的数据文件\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"成功加载{year}年数据: {df.shape[0]}行, {df.shape[1]}列\")\n",
    "        all_data.append(df)\n",
    "    \n",
    "    if not all_data:\n",
    "        raise FileNotFoundError(\"未能找到任何数据文件\")\n",
    "    \n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"合并后数据总量: {df.shape[0]}行, {df.shape[1]}列\")\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"数据预处理\"\"\"\n",
    "    print(\"开始数据预处理...\")\n",
    "\n",
    "    df.columns = df.columns.str.strip()\n",
    "    print(\"修正后的列名:\", df.columns.tolist()) \n",
    "    \n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    df['Datetime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'])\n",
    "    \n",
    "    df['Entries'] = pd.to_numeric(df['Entries'], errors='coerce')\n",
    "    df['Exits'] = pd.to_numeric(df['Exits'], errors='coerce')\n",
    "\n",
    "    print(\"计算客流量增量...\")\n",
    "    df = df.sort_values(by=['C/A', 'Unit', 'SCP', 'Datetime'])\n",
    "    \n",
    "    df['ENTRIES_DIFF'] = df.groupby(['C/A', 'Unit', 'SCP'])['Entries'].diff()\n",
    "    df['EXITS_DIFF'] = df.groupby(['C/A', 'Unit', 'SCP'])['Exits'].diff()\n",
    "    \n",
    "    # 处理异常值\n",
    "    df['ENTRIES_DIFF'] = df['ENTRIES_DIFF'].clip(lower=0)\n",
    "    df['EXITS_DIFF'] = df['EXITS_DIFF'].clip(lower=0)\n",
    "    \n",
    "    max_reasonable_count = 10000\n",
    "    df['ENTRIES_DIFF'] = df['ENTRIES_DIFF'].clip(upper=max_reasonable_count)\n",
    "    df['EXITS_DIFF'] = df['EXITS_DIFF'].clip(upper=max_reasonable_count)\n",
    "    \n",
    "    # 添加时间特征\n",
    "    df['DOW'] = df['Datetime'].dt.dayofweek  # 星期几 (0=周一, 6=周日)\n",
    "    df['HOUR'] = df['Datetime'].dt.hour\n",
    "    df['MONTH'] = df['Datetime'].dt.month\n",
    "    df['YEAR'] = df['Datetime'].dt.year\n",
    "    \n",
    "    df = df.dropna(subset=['ENTRIES_DIFF', 'EXITS_DIFF'])\n",
    "    \n",
    "    print(f\"预处理后数据量: {df.shape[0]}行\")\n",
    "    return df\n",
    "\n",
    "def aggregate_data(df, freq='D'):\n",
    "    \"\"\"\n",
    "    将数据聚合到指定频率\n",
    "    \n",
    "    参数:\n",
    "    df (DataFrame): 预处理后的数据框\n",
    "    freq (str): 聚合频率，'D'表示按天，'H'表示按小时\n",
    "    \n",
    "    返回:\n",
    "    DataFrame: 聚合后的数据框\n",
    "    \"\"\"\n",
    "    print(f\"聚合数据到{freq}频率...\")\n",
    "    \n",
    "    date_col = 'Date' if freq == 'D' else 'Datetime'\n",
    "    \n",
    "    df_agg = df.groupby([date_col, 'Station']).agg({\n",
    "        'ENTRIES_DIFF': 'sum',\n",
    "        'EXITS_DIFF': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    df_agg['TOTAL_TRAFFIC'] = df_agg['ENTRIES_DIFF'] + df_agg['EXITS_DIFF']\n",
    "    \n",
    "    print(f\"聚合后数据量: {df_agg.shape[0]}行\")\n",
    "    return df_agg\n",
    "\n",
    "def analyze_station_traffic(df_agg):\n",
    "    \"\"\"分析各站点客流量\"\"\"\n",
    "    print(\"分析站点客流量...\")\n",
    "    \n",
    "    station_traffic = df_agg.groupby('Station').agg({\n",
    "        'TOTAL_TRAFFIC': 'sum',\n",
    "        'ENTRIES_DIFF': 'sum',\n",
    "        'EXITS_DIFF': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    station_traffic = station_traffic.sort_values('TOTAL_TRAFFIC', ascending=False)\n",
    "    \n",
    "    print(\"客流量最高的10个站点:\")\n",
    "    print(station_traffic.head(10))\n",
    "    \n",
    "    # 普劳特前10个最繁忙的站点\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_stations = station_traffic.head(10)\n",
    "    \n",
    "    # 堆叠条形图\n",
    "    plt.barh(top_stations['Station'], top_stations['ENTRIES_DIFF'], color='skyblue', label='进站')\n",
    "    plt.barh(top_stations['Station'], top_stations['EXITS_DIFF'], left=top_stations['ENTRIES_DIFF'], \n",
    "             color='lightcoral', label='出站')\n",
    "    \n",
    "    plt.xlabel('客流量')\n",
    "    plt.ylabel('站点')\n",
    "    plt.title('纽约地铁最繁忙的10个站点')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('top_stations_traffic.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return station_traffic\n",
    "\n",
    "def prepare_time_series(df_agg, top_n_stations=None, target_station=None):\n",
    "    \"\"\"\n",
    "    准备时间序列数据用于Prophet模型\n",
    "    \n",
    "    参数:\n",
    "    df_agg (DataFrame): 聚合后的数据框\n",
    "    top_n_stations (int): 选取客流量最高的前N个站点，默认为None\n",
    "    target_station (str): 指定分析的目标站点名称，默认为None\n",
    "    \n",
    "    返回:\n",
    "    DataFrame: 符合Prophet要求格式的数据框\n",
    "    \"\"\"\n",
    "    print(\"准备时间序列数据...\")\n",
    "    \n",
    "    # 如果指定了目标站点\n",
    "    if target_station:\n",
    "        df_station = df_agg[df_agg['Station'] == target_station].copy()\n",
    "        if df_station.empty:\n",
    "            print(f\"警告: 未找到站点 '{target_station}'，将使用总体数据\")\n",
    "            df_station = df_agg.copy()\n",
    "    \n",
    "    # 如果已经指定要选取top N站点了\n",
    "    elif top_n_stations:\n",
    "        # 找出客流量最高的N个站点\n",
    "        top_stations = analyze_station_traffic(df_agg)['Station'].head(top_n_stations).tolist()\n",
    "        df_station = df_agg[df_agg['Station'].isin(top_stations)].copy()\n",
    "    \n",
    "    # 否则的话使用所有站点的总和\n",
    "    else:\n",
    "        df_station = df_agg.copy()\n",
    "        \n",
    "    # 然后按日期聚合所有选中站点的客流量\n",
    "    ts_data = df_station.groupby('Date').agg({\n",
    "        'ENTRIES_DIFF': 'sum',\n",
    "        'EXITS_DIFF': 'sum',\n",
    "        'TOTAL_TRAFFIC': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # 这是Prophet要求的格式: ds (日期) 和 y (预测目标) 好像要求时间戳格式🤔\n",
    "    prophet_df = ts_data.rename(columns={'Date': 'ds', 'TOTAL_TRAFFIC': 'y'})\n",
    "    \n",
    "    print(f\"时间序列数据范围: {prophet_df['ds'].min()} 到 {prophet_df['ds'].max()}\")\n",
    "    return prophet_df\n",
    "\n",
    "def add_holidays(df):\n",
    "    \"\"\"添加美国假日信息到数据框\"\"\"\n",
    "    print(\"添加假日信息...\")\n",
    "    \n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "\n",
    "    start_year = df['ds'].min().year\n",
    "    end_year = df['ds'].max().year\n",
    "    \n",
    "    # 获取大漂亮的假日\n",
    "    us_holidays = holidays.US(years=range(start_year, end_year + 1))\n",
    "    \n",
    "    # 先构造一个假日数据框 集中处理\n",
    "    holiday_df = pd.DataFrame(\n",
    "        [(pd.Timestamp(date), name) for date, name in us_holidays.items()],\n",
    "        columns=['ds', 'holiday']\n",
    "    )\n",
    "    \n",
    "    # 添加假日前后的影响天数\n",
    "    holiday_df['lower_window'] = -1  # 假日前一天\n",
    "    holiday_df['upper_window'] = 1   # 假日后一天\n",
    "    \n",
    "    # 重要假日影响应该会大一点 就多一天吧 重要假日是我猜的（like the fourth of July~\n",
    "    important_holidays = ['New Year', 'Independence Day', 'Thanksgiving', 'Christmas Day']\n",
    "    for holiday in important_holidays:\n",
    "        mask = holiday_df['holiday'].str.contains(holiday, case=False, na=False)\n",
    "        holiday_df.loc[mask, 'lower_window'] = -2  # 重要假日前两天\n",
    "        holiday_df.loc[mask, 'upper_window'] = 2   # 重要假日后两天\n",
    "\n",
    "    print(\"假日数据预览:\")\n",
    "    print(holiday_df.head())\n",
    "    print(\"假日数据列名:\", holiday_df.columns.tolist())\n",
    "    \n",
    "    return holiday_df\n",
    "    \n",
    "def train_prophet_model(df, forecast_periods=60, holidays_df=None):\n",
    "    \"\"\"\n",
    "    训练Prophet模型并进行预测\n",
    "    \n",
    "    参数:\n",
    "    df (DataFrame): 符合Prophet格式的数据\n",
    "    forecast_periods (int): 预测的天数\n",
    "    holidays_df (DataFrame): 假日数据框\n",
    "    \n",
    "    返回:\n",
    "    tuple: (Prophet模型, 预测结果)\n",
    "    \"\"\"\n",
    "    print(\"训练Prophet模型...\")\n",
    "    \n",
    "    # Prophet建模\n",
    "    model = Prophet(\n",
    "        changepoint_prior_scale=0.05,  # 控制趋势灵活性\n",
    "        seasonality_prior_scale=10,    # 增强季节性\n",
    "        seasonality_mode='multiplicative',  # 乘法季节性通常更适合客流量\n",
    "        daily_seasonality=True,        # 启用日内季节性\n",
    "        weekly_seasonality=True,       # 启用周季节性\n",
    "        yearly_seasonality=True        # 启用年季节性\n",
    "    )\n",
    "    \n",
    "    # 添加月季节性\n",
    "    model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "    \n",
    "    # 添加季度季节性\n",
    "    model.add_seasonality(name='quarterly', period=91.25, fourier_order=5)\n",
    "    \n",
    "    # 添加假日效应\n",
    "    if holidays_df is not None:\n",
    "        model.add_country_holidays(country_name='US')\n",
    "        model.holidays = holidays_df\n",
    "    \n",
    "    model.fit(df)\n",
    "    \n",
    "    future = model.make_future_dataframe(periods=forecast_periods)\n",
    "    \n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    print(f\"模型训练完成，预测未来{forecast_periods}天\")\n",
    "    print(\"预测结果列:\", forecast.columns.tolist())\n",
    "    return model, forecast\n",
    "\n",
    "def visualize_forecast(model, forecast, df, title='地铁客流量预测'):\n",
    "    \"\"\"可视化预测结果\"\"\"\n",
    "    print(\"可视化预测结果...\")\n",
    "    \n",
    "    # 普劳特预测总图 似乎普劳特不出汉语 但我已经设置过了 仍是一个bug\n",
    "    fig1 = model.plot(forecast)\n",
    "    plt.title(f'{title} - Tendency Chart')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Ridership')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prophet_forecast.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 普劳特组件图\n",
    "    fig2 = model.plot_components(forecast)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prophet_components.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 最近一年的实际值与预测值对比图吧\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # 先筛选出最近一年的数据\n",
    "    last_date = df['ds'].max()\n",
    "    one_year_ago = last_date - pd.Timedelta(days=365)\n",
    "    \n",
    "    # 然后提取最近一年的实际值和预测值\n",
    "    recent_actual = df[df['ds'] >= one_year_ago]\n",
    "    recent_forecast = forecast[(forecast['ds'] >= one_year_ago) & (forecast['ds'] <= last_date)]\n",
    "    \n",
    "    # 普劳特出实际值\n",
    "    plt.plot(recent_actual['ds'], recent_actual['y'], 'k.', label='Actual Ridership')\n",
    "    \n",
    "    # 普劳特预测值及其置信区间\n",
    "    plt.plot(recent_forecast['ds'], recent_forecast['yhat'], 'b-', label='Predict Ridership')\n",
    "    plt.fill_between(recent_forecast['ds'], recent_forecast['yhat_lower'], recent_forecast['yhat_upper'], \n",
    "                    color='blue', alpha=0.2, label='95% Confidence Interval')\n",
    "    \n",
    "    plt.title(f'{title} - Trend over the Past Year')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Ridership')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('recent_year_comparison.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 普劳特未来预测\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # 提取未来的预测值\n",
    "    future_forecast = forecast[forecast['ds'] > last_date]\n",
    "    \n",
    "    # 普劳特预测值及其置信区间\n",
    "    plt.plot(future_forecast['ds'], future_forecast['yhat'], 'r-', label='Future Ridership Forecast')\n",
    "    plt.fill_between(future_forecast['ds'], future_forecast['yhat_lower'], future_forecast['yhat_upper'], \n",
    "                    color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "    \n",
    "    plt.title(f'{title} - Future Ridership Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Ridership')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('future_forecast.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 输出为交互式Plotly图表(保存为HTML)\n",
    "    try:\n",
    "        fig = plot_plotly(model, forecast)\n",
    "        fig.update_layout(title=f'{title} - 交互式预测图')\n",
    "        py.plot(fig, filename='interactive_forecast.html', auto_open=False)\n",
    "        \n",
    "        components_fig = plot_components_plotly(model, forecast)\n",
    "        components_fig.update_layout(title=f'{title} - 交互式组件分解图')\n",
    "        py.plot(components_fig, filename='interactive_components.html', auto_open=False)\n",
    "        \n",
    "        print(\"已生成交互式HTML可视化\")\n",
    "    except Exception as e:\n",
    "        print(f\"生成交互式图表时出错: {e}\")\n",
    "    \n",
    "def analyze_holiday_effects(forecast):\n",
    "    print(\"分析假日效应...\")\n",
    "    \n",
    "    # 查找包含假日效应的列（通常以假日名称或 'holidays' 开头）\n",
    "    holiday_cols = [col for col in forecast.columns if 'holidays' in col.lower() or any(h in col.lower() for h in ['new year', 'independence', 'thanksgiving', 'christmas'])]\n",
    "    \n",
    "    if not holiday_cols:\n",
    "        print(\"未找到假日效应列，可能是假日未正确配置\")\n",
    "        return None\n",
    "    \n",
    "    print(\"找到的假日效应列:\", holiday_cols)\n",
    "    \n",
    "    # 假设假日效应汇总在 'holidays' 列或单独的假日列\n",
    "    holiday_effects = forecast[holiday_cols + ['ds']].copy()\n",
    "    holiday_effects = holiday_effects[holiday_effects[holiday_cols].notna().any(axis=1)]\n",
    "    \n",
    "    # 如果有多个假日列，汇总总效应\n",
    "    if len(holiday_cols) > 1:\n",
    "        holiday_effects['holiday_effect'] = holiday_effects[holiday_cols].sum(axis=1)\n",
    "    else:\n",
    "        holiday_effects['holiday_effect'] = holiday_effects[holiday_cols[0]]\n",
    "    \n",
    "    # 按效应绝对值排序\n",
    "    holiday_effects['abs_effect'] = holiday_effects['holiday_effect'].abs()\n",
    "    holiday_effects = holiday_effects.sort_values('abs_effect', ascending=False)\n",
    "    \n",
    "    print(\"假日效应最显著的10个日期:\")\n",
    "    print(holiday_effects[['ds', 'holiday_effect', 'abs_effect']].head(10))\n",
    "    \n",
    "    # 可视化\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_holidays = holiday_effects.head(15)\n",
    "    plt.barh(top_holidays['ds'].dt.strftime('%Y-%m-%d'), \n",
    "             top_holidays['holiday_effect'], color='skyblue')\n",
    "    \n",
    "    plt.xlabel('Ridership Changes')\n",
    "    plt.ylabel('Date')\n",
    "    plt.title('The Impact of Holidays on Subway Ridership')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('holiday_effects.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return holiday_effects\n",
    "\n",
    "def evaluate_model(df, forecast):\n",
    "    \"\"\"评估模型性能\"\"\"\n",
    "    print(\"评估模型性能...\")\n",
    "    \n",
    "    # 将预测结果与实际值合并\n",
    "    evaluation = pd.merge(\n",
    "        df[['ds', 'y']], \n",
    "        forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], \n",
    "        on='ds', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 计算评估指标\n",
    "    evaluation['error'] = evaluation['y'] - evaluation['yhat']\n",
    "    evaluation['abs_error'] = np.abs(evaluation['error'])\n",
    "    evaluation['squared_error'] = evaluation['error'] ** 2\n",
    "    \n",
    "    # 计算MAE, RMSE, MAPE\n",
    "    mae = evaluation['abs_error'].mean()\n",
    "    rmse = np.sqrt(evaluation['squared_error'].mean())\n",
    "    # 避免除以零\n",
    "    evaluation['abs_pct_error'] = evaluation['abs_error'] / evaluation['y'].replace(0, np.nan) * 100\n",
    "    mape = evaluation['abs_pct_error'].mean()\n",
    "    \n",
    "    print(f\"平均绝对误差 (MAE): {mae:.2f}\")\n",
    "    print(f\"均方根误差 (RMSE): {rmse:.2f}\")\n",
    "    print(f\"平均绝对百分比误差 (MAPE): {mape:.2f}%\")\n",
    "    \n",
    "    # 检查预测区间覆盖率\n",
    "    evaluation['in_range'] = (evaluation['y'] >= evaluation['yhat_lower']) & (evaluation['y'] <= evaluation['yhat_upper'])\n",
    "    coverage = evaluation['in_range'].mean() * 100\n",
    "    print(f\"95%置信区间覆盖率: {coverage:.2f}%\")\n",
    "    \n",
    "    # 绘制误差直方图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(evaluation['error'], bins=50, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(0, color='red', linestyle='--')\n",
    "    plt.xlabel('Forecast Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Prediction Error Distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('error_distribution.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 绘制真实值与预测值的散点图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(evaluation['y'], evaluation['yhat'], alpha=0.5)\n",
    "    \n",
    "    # 添加对角线\n",
    "\n",
    "    max_val = max(evaluation['y'].max(), evaluation['yhat'].max())\n",
    "    min_val = min(evaluation['y'].min(), evaluation['yhat'].min())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    \n",
    "    plt.xlabel('Actual Ridership')\n",
    "    plt.ylabel('Predict Ridership')\n",
    "    plt.title('Actual vs Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('actual_vs_predicted.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'Coverage': coverage\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    try:\n",
    "        # 1. 加载数据\n",
    "        df = load_turnstile_data()\n",
    "        \n",
    "        # 2. 数据预处理\n",
    "        df_processed = preprocess_data(df)\n",
    "        \n",
    "        # 3. 按天聚合数据\n",
    "        df_daily = aggregate_data(df_processed, freq='D')\n",
    "        \n",
    "        # 4. 分析站点客流量\n",
    "        station_traffic = analyze_station_traffic(df_daily)\n",
    "        \n",
    "        # 5. 选择分析方式\n",
    "        # 可以修改为分析特定站点或者Top N站点\n",
    "        # prophet_df = prepare_time_series(df_daily, target_station=\"34 ST-PENN STA\")\n",
    "        # prophet_df = prepare_time_series(df_daily, top_n_stations=5)\n",
    "        prophet_df = prepare_time_series(df_daily)  # 分析所有站点总流量\n",
    "        \n",
    "        # 6. 添加假日信息\n",
    "        holidays_df = add_holidays(prophet_df)\n",
    "        \n",
    "        # 7. 训练Prophet模型并预测\n",
    "        model, forecast = train_prophet_model(prophet_df, forecast_periods=90, holidays_df=holidays_df)\n",
    "        \n",
    "        # 8. 可视化预测结果\n",
    "        visualize_forecast(model, forecast, prophet_df, title='纽约地铁客流量预测')\n",
    "        \n",
    "        # 9. 分析假日效应\n",
    "        holiday_effects = analyze_holiday_effects(forecast)\n",
    "        \n",
    "        # 10. 评估模型性能\n",
    "        metrics = evaluate_model(prophet_df, forecast)\n",
    "        \n",
    "        print(\"\\n分析完成! 已生成多个可视化图表。\")\n",
    "        \n",
    "        # 11. 保存预测结果到CSV\n",
    "        forecast.to_csv('prophet_forecast_results.csv', index=False)\n",
    "        print(\"预测结果已保存到 'prophet_forecast_results.csv'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"程序执行过程中出错: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2577053f-f1a0-4231-afd4-2d737873ece6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forecast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m holiday_effects\n\u001b[0;32m---> 42\u001b[0m holiday_effects \u001b[38;5;241m=\u001b[39m analyze_holiday_effects(forecast)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'forecast' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "605a98cb-7f6d-4c32-b7a2-3dfa818bd875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C列的所有唯一值（存入列表）：\n",
      "['02-00-00', '02-00-01', '02-03-00', '02-03-01', '02-03-02', '02-03-03', '02-03-04', '02-03-05', '02-03-06', '02-04-00', '02-05-00', '02-05-01', '02-06-00', '02-07-00', '02-07-01', '00-00-00', '00-00-01', '00-00-02', '00-00-03', '00-00-04', '00-03-00', '00-03-01', '00-03-02', '00-04-00', '00-07-00', '00-07-01', '00-07-02', '01-04-00', '01-05-00', '01-05-01', '01-06-00', '01-06-01', '01-06-02', '01-06-03', '01-07-00', '00-00-05', '00-00-06', '00-00-07', '01-00-00', '01-00-01', '01-00-02', '01-00-03', '01-00-04', '01-00-05', '01-04-01', '01-07-01', '01-03-00', '01-03-01', '01-03-02', '02-00-02', '02-06-01', '03-00-00', '03-00-01', '03-00-02', '03-04-00', '03-05-00', '03-06-00', '03-06-01', '03-07-00', '01-00-06', '01-00-07', '01-04-02', '01-07-02', '01-03-03', '00-04-01', '02-00-03', '02-00-04', '02-00-05', '02-04-01', '03-03-00', '03-03-01', '03-03-02', '03-04-01', '03-06-02', '03-07-01', '05-00-00', '05-00-01', '05-00-02', '05-00-03', '05-07-00', '05-07-01', '05-07-02', '00-06-00', '00-03-03', '00-03-04', '00-05-00', '00-05-01', '00-05-02', '00-05-03', '00-06-01', '00-06-02', '00-06-03', '00-06-04', '00-06-05', '00-06-06', '00-06-07', '00-06-08', '00-07-03', '00-07-04', '00-07-05', '02-01-00', '02-01-01', '02-01-02', '02-04-02', '00-02-00', '00-02-01', '00-04-02', '02-06-02', '04-00-00', '04-00-01', '04-00-02', '04-00-03', '04-00-04', '04-04-00', '04-04-01', '04-05-00', '04-05-01', '04-07-00', '04-07-01', '05-04-00', '05-05-00', '05-05-01', '05-06-00', '05-06-01', '02-07-02', '03-00-03', '03-03-03', '03-05-01', '01-05-02', '00-04-03', '01-02-00', '01-02-01', '01-02-02', '01-03-04', '01-04-03', '02-07-03', '02-07-04', '02-07-05', '00-00-08', '00-00-09', '00-04-04', '05-03-00', '05-03-01', '05-03-02', '05-03-03', '05-03-04', '05-03-05', '05-03-06', '05-04-01', '05-04-02', '05-07-03', '02-00-06', '02-00-07', '02-00-08', '03-00-04', '03-00-05', '01-06-04', '01-07-03', '00-03-05', '00-03-06', '00-03-07', '00-03-08', '01-03-05', '00-00-0A', '00-00-0B', '01-01-00', '01-01-01', '00-02-02', '02-01-03', '02-06-03', '02-06-04', '02-06-05', '02-06-06', '00-07-06', '02-00-09', '00-05-04', '00-05-05', '01-01-02', '01-01-03', '01-05-03', '00-01-02', '00-01-03', '00-01-04', '00-01-05', '00-01-06', '00-02-03', '00-02-04', '00-02-05', '00-01-00', '00-01-01', '00-04-05', '00-01-07', '00-01-08', '00-04-06', '00-04-07', '00-04-08', '00-04-09', '01-00-08', '01-01-04', '01-01-05', '01-01-06', '01-01-07', '01-02-03', '01-02-04', '01-00-09', '01-00-0A', '02-01-04', '02-01-05', '02-01-06', '02-01-07', '02-02-00', '02-02-01', '02-02-02', '02-02-03', '02-02-04', '03-00-06', '03-00-07', '03-01-00', '03-01-01', '03-01-02', '03-01-03', '03-01-04', '03-01-05', '03-01-06', '03-01-07', '01-04-0A', '01-06-05', '01-06-06', '03-07-02', '04-06-00', '04-07-02', '04-00-05', '04-00-06', '04-02-00', '04-02-01', '04-02-02', '04-02-03', '04-03-00', '04-03-01', '02-05-02', '01-D6-06', '05-00-04', '05-00-05', '00-FF-01', '02-03-07', '01-03-06']\n",
      "\n",
      "C列各值的行数：\n",
      "值: 00-00-00, 行数: 949986\n",
      "值: 00-00-01, 行数: 921939\n",
      "值: 00-00-02, 行数: 846832\n",
      "值: 00-00-03, 行数: 391029\n",
      "值: 00-07-00, 行数: 324381\n",
      "值: 00-03-00, 行数: 294244\n",
      "值: 01-00-00, 行数: 284399\n",
      "值: 01-00-01, 行数: 283782\n",
      "值: 00-03-01, 行数: 277417\n",
      "值: 01-00-02, 行数: 272281\n",
      "值: 00-04-00, 行数: 260063\n",
      "值: 00-05-00, 行数: 251595\n",
      "值: 00-07-01, 行数: 243634\n",
      "值: 00-06-00, 行数: 234867\n",
      "值: 00-05-01, 行数: 231569\n",
      "值: 01-06-00, 行数: 226824\n",
      "值: 00-00-04, 行数: 225830\n",
      "值: 01-06-01, 行数: 203738\n",
      "值: 00-03-02, 行数: 185703\n",
      "值: 00-06-01, 行数: 156508\n",
      "值: 01-05-00, 行数: 140838\n",
      "值: 00-04-01, 行数: 134359\n",
      "值: 01-07-00, 行数: 132747\n",
      "值: 01-05-01, 行数: 130626\n",
      "值: 01-00-03, 行数: 118243\n",
      "值: 00-03-03, 行数: 98522\n",
      "值: 00-00-05, 行数: 96499\n",
      "值: 01-04-00, 行数: 87429\n",
      "值: 01-03-00, 行数: 85724\n",
      "值: 01-07-01, 行数: 85443\n",
      "值: 02-00-00, 行数: 76447\n",
      "值: 00-06-02, 行数: 72210\n",
      "值: 01-03-01, 行数: 70878\n",
      "值: 01-00-04, 行数: 70792\n",
      "值: 02-00-01, 行数: 69044\n",
      "值: 02-00-02, 行数: 64796\n",
      "值: 01-06-02, 行数: 62412\n",
      "值: 00-03-04, 行数: 58072\n",
      "值: 00-00-06, 行数: 57701\n",
      "值: 01-03-02, 行数: 51560\n",
      "值: 02-06-00, 行数: 48695\n",
      "值: 00-07-02, 行数: 48487\n",
      "值: 00-04-02, 行数: 48241\n",
      "值: 02-00-03, 行数: 46810\n",
      "值: 00-00-07, 行数: 45601\n",
      "值: 02-06-01, 行数: 43646\n",
      "值: 00-05-02, 行数: 43514\n",
      "值: 02-05-00, 行数: 37607\n",
      "值: 01-04-01, 行数: 36957\n",
      "值: 01-00-05, 行数: 35628\n",
      "值: 02-07-00, 行数: 34980\n",
      "值: 00-06-03, 行数: 34747\n",
      "值: 02-00-04, 行数: 34146\n",
      "值: 02-05-01, 行数: 33985\n",
      "值: 00-05-03, 行数: 32364\n",
      "值: 01-03-03, 行数: 31496\n",
      "值: 02-03-00, 行数: 30932\n",
      "值: 02-03-01, 行数: 30231\n",
      "值: 01-06-03, 行数: 28632\n",
      "值: 03-00-00, 行数: 25408\n",
      "值: 03-00-02, 行数: 24495\n",
      "值: 03-00-01, 行数: 24491\n",
      "值: 00-04-03, 行数: 23299\n",
      "值: 00-03-05, 行数: 23005\n",
      "值: 00-02-00, 行数: 22965\n",
      "值: 02-07-01, 行数: 22951\n",
      "值: 02-00-05, 行数: 22133\n",
      "值: 00-00-08, 行数: 21864\n",
      "值: 01-00-06, 行数: 21718\n",
      "值: 02-04-00, 行数: 21555\n",
      "值: 02-03-02, 行数: 20168\n",
      "值: 03-06-00, 行数: 19678\n",
      "值: 00-02-01, 行数: 19296\n",
      "值: 00-07-03, 行数: 19280\n",
      "值: 03-06-01, 行数: 17682\n",
      "值: 02-03-03, 行数: 16288\n",
      "值: 03-03-00, 行数: 16057\n",
      "值: 02-06-02, 行数: 15888\n",
      "值: 00-00-09, 行数: 15827\n",
      "值: 00-04-04, 行数: 15690\n",
      "值: 01-03-04, 行数: 15353\n",
      "值: 03-03-01, 行数: 15042\n",
      "值: 00-04-05, 行数: 14781\n",
      "值: 00-01-00, 行数: 13793\n",
      "值: 00-03-06, 行数: 13721\n",
      "值: 03-03-02, 行数: 13641\n",
      "值: 01-07-02, 行数: 12850\n",
      "值: 01-00-07, 行数: 12368\n",
      "值: 02-04-01, 行数: 12208\n",
      "值: 04-00-02, 行数: 12016\n",
      "值: 04-00-01, 行数: 12001\n",
      "值: 04-00-00, 行数: 11907\n",
      "值: 00-00-0A, 行数: 11780\n",
      "值: 03-05-00, 行数: 11762\n",
      "值: 01-01-01, 行数: 11669\n",
      "值: 01-01-00, 行数: 11652\n",
      "值: 03-07-00, 行数: 11558\n",
      "值: 00-01-03, 行数: 11347\n",
      "值: 00-01-05, 行数: 11218\n",
      "值: 00-01-01, 行数: 11124\n",
      "值: 00-01-02, 行数: 10733\n",
      "值: 00-06-04, 行数: 10258\n",
      "值: 00-01-04, 行数: 10075\n",
      "值: 02-00-06, 行数: 10070\n",
      "值: 04-00-03, 行数: 10006\n",
      "值: 03-00-03, 行数: 9923\n",
      "值: 01-00-08, 行数: 9733\n",
      "值: 03-05-01, 行数: 9610\n",
      "值: 00-01-06, 行数: 9526\n",
      "值: 01-02-01, 行数: 9169\n",
      "值: 01-02-00, 行数: 9159\n",
      "值: 00-07-04, 行数: 8616\n",
      "值: 01-02-02, 行数: 8433\n",
      "值: 00-06-05, 行数: 8215\n",
      "值: 04-00-04, 行数: 7988\n",
      "值: 03-00-05, 行数: 7913\n",
      "值: 01-01-03, 行数: 7691\n",
      "值: 00-01-07, 行数: 7618\n",
      "值: 00-03-07, 行数: 7608\n",
      "值: 01-04-02, 行数: 7227\n",
      "值: 03-04-00, 行数: 7181\n",
      "值: 00-04-06, 行数: 7162\n",
      "值: 04-05-00, 行数: 6812\n",
      "值: 01-03-05, 行数: 6674\n",
      "值: 03-07-01, 行数: 6507\n",
      "值: 00-04-07, 行数: 6459\n",
      "值: 03-00-04, 行数: 6145\n",
      "值: 05-00-03, 行数: 6101\n",
      "值: 00-05-04, 行数: 6101\n",
      "值: 05-00-00, 行数: 6099\n",
      "值: 05-00-02, 行数: 6097\n",
      "值: 02-03-04, 行数: 6086\n",
      "值: 04-05-01, 行数: 6085\n",
      "值: 05-00-01, 行数: 6085\n",
      "值: 00-00-0B, 行数: 6078\n",
      "值: 02-00-07, 行数: 6036\n",
      "值: 02-00-08, 行数: 6032\n",
      "值: 01-01-02, 行数: 5986\n",
      "值: 01-00-09, 行数: 5939\n",
      "值: 02-07-02, 行数: 5859\n",
      "值: 00-04-09, 行数: 5710\n",
      "值: 00-01-08, 行数: 5708\n",
      "值: 00-04-08, 行数: 5662\n",
      "值: 03-03-03, 行数: 5481\n",
      "值: 00-02-02, 行数: 5085\n",
      "值: 00-07-05, 行数: 5063\n",
      "值: 01-06-04, 行数: 4643\n",
      "值: 02-01-02, 行数: 4520\n",
      "值: 02-01-01, 行数: 4517\n",
      "值: 02-01-00, 行数: 4479\n",
      "值: 01-02-03, 行数: 4327\n",
      "值: 04-07-01, 行数: 4325\n",
      "值: 04-07-00, 行数: 4287\n",
      "值: 00-05-05, 行数: 4081\n",
      "值: 02-06-03, 行数: 4036\n",
      "值: 02-03-05, 行数: 4035\n",
      "值: 02-03-06, 行数: 4034\n",
      "值: 00-06-06, 行数: 4033\n",
      "值: 04-00-05, 行数: 3931\n",
      "值: 03-01-01, 行数: 3919\n",
      "值: 02-05-02, 行数: 3907\n",
      "值: 03-01-02, 行数: 3898\n",
      "值: 03-01-00, 行数: 3891\n",
      "值: 01-01-05, 行数: 3813\n",
      "值: 03-01-03, 行数: 3808\n",
      "值: 01-01-04, 行数: 3796\n",
      "值: 01-01-06, 行数: 3781\n",
      "值: 01-02-04, 行数: 3754\n",
      "值: 04-04-00, 行数: 3620\n",
      "值: 00-03-08, 行数: 3574\n",
      "值: 00-07-06, 行数: 3557\n",
      "值: 00-02-03, 行数: 3038\n",
      "值: 01-05-02, 行数: 2746\n",
      "值: 02-07-03, 行数: 2730\n",
      "值: 00-02-04, 行数: 2491\n",
      "值: 02-04-02, 行数: 2354\n",
      "值: 05-07-00, 行数: 2179\n",
      "值: 01-04-03, 行数: 2139\n",
      "值: 03-04-01, 行数: 2138\n",
      "值: 04-04-01, 行数: 2138\n",
      "值: 05-03-06, 行数: 2105\n",
      "值: 05-03-05, 行数: 2105\n",
      "值: 05-03-00, 行数: 2104\n",
      "值: 05-03-01, 行数: 2104\n",
      "值: 05-03-02, 行数: 2103\n",
      "值: 05-03-04, 行数: 2103\n",
      "值: 05-03-03, 行数: 2098\n",
      "值: 04-03-00, 行数: 2030\n",
      "值: 04-03-01, 行数: 2029\n",
      "值: 04-02-02, 行数: 2028\n",
      "值: 04-00-06, 行数: 2028\n",
      "值: 01-05-03, 行数: 2025\n",
      "值: 02-00-09, 行数: 2023\n",
      "值: 02-06-06, 行数: 2023\n",
      "值: 02-06-05, 行数: 2023\n",
      "值: 02-06-04, 行数: 2023\n",
      "值: 02-03-07, 行数: 2022\n",
      "值: 04-02-00, 行数: 2020\n",
      "值: 04-02-01, 行数: 2017\n",
      "值: 00-06-07, 行数: 2016\n",
      "值: 04-02-03, 行数: 2013\n",
      "值: 05-06-01, 行数: 2013\n",
      "值: 01-03-06, 行数: 2011\n",
      "值: 03-06-02, 行数: 2011\n",
      "值: 00-06-08, 行数: 2011\n",
      "值: 05-05-00, 行数: 2011\n",
      "值: 05-06-00, 行数: 2011\n",
      "值: 02-01-03, 行数: 2009\n",
      "值: 05-05-01, 行数: 2009\n",
      "值: 04-06-00, 行数: 2006\n",
      "值: 05-00-05, 行数: 2001\n",
      "值: 05-00-04, 行数: 2001\n",
      "值: 02-01-04, 行数: 1907\n",
      "值: 01-01-07, 行数: 1906\n",
      "值: 02-02-03, 行数: 1906\n",
      "值: 02-01-06, 行数: 1906\n",
      "值: 02-02-02, 行数: 1906\n",
      "值: 02-02-04, 行数: 1905\n",
      "值: 03-00-07, 行数: 1905\n",
      "值: 02-01-05, 行数: 1905\n",
      "值: 02-01-07, 行数: 1905\n",
      "值: 03-01-04, 行数: 1904\n",
      "值: 03-00-06, 行数: 1903\n",
      "值: 02-02-01, 行数: 1902\n",
      "值: 01-00-0A, 行数: 1900\n",
      "值: 03-01-07, 行数: 1900\n",
      "值: 03-01-05, 行数: 1893\n",
      "值: 03-01-06, 行数: 1890\n",
      "值: 02-02-00, 行数: 1890\n",
      "值: 05-07-02, 行数: 1467\n",
      "值: 05-07-01, 行数: 1466\n",
      "值: 05-04-00, 行数: 1445\n",
      "值: 01-07-03, 行数: 1262\n",
      "值: 05-04-02, 行数: 753\n",
      "值: 05-07-03, 行数: 747\n",
      "值: 02-07-05, 行数: 736\n",
      "值: 05-04-01, 行数: 724\n",
      "值: 03-07-02, 行数: 723\n",
      "值: 02-07-04, 行数: 710\n",
      "值: 04-07-02, 行数: 700\n",
      "值: 01-04-0A, 行数: 589\n",
      "值: 00-02-05, 行数: 583\n",
      "值: 01-06-05, 行数: 568\n",
      "值: 01-06-06, 行数: 542\n",
      "值: 01-D6-06, 行数: 1\n",
      "值: 00-FF-01, 行数: 1\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 设置 CSV 文件路径\n",
    "csv_file = \"/Users/dl/Desktop/turnstile-usage-data-2014.csv\"  # 替换为你的 CSV 文件路径\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 确保第3列（C列）存在\n",
    "if df.shape[1] < 3:\n",
    "    raise ValueError(\"CSV file does not have at least 3 columns!\")\n",
    "\n",
    "# 获取第3列（C列，索引为2）的所有唯一值并存入列表\n",
    "column_c = df.iloc[:, 2]  # 第3列\n",
    "unique_values_list = column_c.unique().tolist()\n",
    "\n",
    "# 步骤 1：打印唯一值列表\n",
    "print(\"C列的所有唯一值（存入列表）：\")\n",
    "print(unique_values_list)\n",
    "\n",
    "# 步骤 2：根据C列内容匹配并计算行数\n",
    "print(\"\\nC列各值的行数：\")\n",
    "value_counts = column_c.value_counts()\n",
    "for value, count in value_counts.items():\n",
    "    print(f\"值: {value}, 行数: {count}\")\n",
    "\n",
    "print(len(unique_values_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5835cf-f55e-4766-8cd1-6dc3e5bb514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到以下数据文件: ['turnstile-usage-data-2015.csv', 'turnstile-usage-data-2014.csv', 'turnstile-usage-data-2016.csv', 'turnstile-usage-data-2017.csv', 'turnstile-usage-data-2018.csv']\n",
      "正在加载数据...\n",
      "加载完成，共 49244141 条记录。\n",
      "正在预处理数据...\n",
      "修正后的列名: ['C/A', 'Unit', 'SCP', 'Station', 'Line Name', 'Division', 'Date', 'Time', 'Description', 'Entries', 'Exits']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. 数据加载与预处理\n",
    "def load_turnstile_data(file_paths):\n",
    "    \"\"\"\n",
    "    加载MTA地铁闸机数据并合并\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        all_data.append(df)\n",
    "    \n",
    "    # 合并所有数据集\n",
    "    df_combined = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    return df_combined\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    预处理MTA地铁闸机数据\n",
    "    \"\"\"\n",
    "    df.columns = df.columns.str.strip()\n",
    "    print(\"修正后的列名:\", df.columns.tolist())\n",
    "    \n",
    "    # 转换日期和时间为datetime对象\n",
    "    df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "    \n",
    "    # 排序数据\n",
    "    df = df.sort_values(by=['C/A', 'Unit', 'SCP', 'Datetime'])\n",
    "    \n",
    "    # 计算每个闸机每个时间段的实际进出站人数（差值）\n",
    "    df['PREV_ENTRIES'] = df.groupby(['C/A', 'Unit', 'SCP'])['Entries'].shift(1)\n",
    "    df['PREV_EXITS'] = df.groupby(['C/A', 'Unit', 'SCP'])['Exits'].shift(1)\n",
    "    \n",
    "    # 计算进出站人数差值\n",
    "    df['ENTRIES_DIFF'] = df['Entries'] - df['PREV_ENTRIES']\n",
    "    df['EXITS_DIFF'] = df['Exits'] - df['PREV_EXITS']\n",
    "    \n",
    "    # 处理异常值（负值或过大值）\n",
    "    df.loc[df['ENTRIES_DIFF'] < 0, 'ENTRIES_DIFF'] = 0\n",
    "    df.loc[df['EXITS_DIFF'] < 0, 'EXITS_DIFF'] = 0\n",
    "    df.loc[df['ENTRIES_DIFF'] > 5000, 'ENTRIES_DIFF'] = 0\n",
    "    df.loc[df['EXITS_DIFF'] > 5000, 'EXITS_DIFF'] = 0\n",
    "    \n",
    "    # 删除缺失值\n",
    "    df = df.dropna(subset=['ENTRIES_DIFF', 'EXITS_DIFF'])\n",
    "    \n",
    "    # 提取日期特征\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Hour'] = df['Datetime'].dt.hour\n",
    "    df['Day'] = df['Datetime'].dt.day\n",
    "    df['Month'] = df['Datetime'].dt.month\n",
    "    df['Year'] = df['Datetime'].dt.year\n",
    "    df['Dayofweek'] = df['Datetime'].dt.dayofweek  # 0=周一，6=周日\n",
    "    \n",
    "    return df\n",
    "\n",
    "def aggregate_by_station(df, time_interval='D'):\n",
    "    \"\"\"\n",
    "    按车站和时间间隔聚合数据\n",
    "    time_interval: 'D'为日，'H'为小时\n",
    "    \"\"\"\n",
    "    # 设置时间索引后重采样\n",
    "    if time_interval == 'D':\n",
    "        # 日聚合\n",
    "        df_agg = df.groupby(['Station', pd.Grouper(key='Datetime', freq='D')])[['ENTRIES_DIFF', 'EXITS_DIFF']].sum().reset_index()\n",
    "    elif time_interval == 'H':\n",
    "        # 小时聚合\n",
    "        df_agg = df.groupby(['Station', pd.Grouper(key='Datetime', freq='H')])[['ENTRIES_DIFF', 'EXITS_DIFF']].sum().reset_index()\n",
    "    \n",
    "    # 计算总流量（进站+出站）\n",
    "    df_agg['TOTAL_FLOW'] = df_agg['ENTRIES_DIFF'] + df_agg['EXITS_DIFF']\n",
    "    \n",
    "    return df_agg\n",
    "\n",
    "# 2. 特定车站数据提取和特征工程\n",
    "def prepare_station_data(df_agg, station_name, target_col='TOTAL_FLOW'):\n",
    "    \"\"\"\n",
    "    准备特定车站的数据用于时间序列预测\n",
    "    \"\"\"\n",
    "    # 提取特定车站数据\n",
    "    station_data = df_agg[df_agg['Station'] == station_name].copy()\n",
    "    \n",
    "    # 确保数据时间上是连续的\n",
    "    station_data = station_data.set_index('Datetime').sort_index()\n",
    "    \n",
    "    # 重采样以确保没有缺失的时间点\n",
    "    if 'D' in station_data.index.freq or station_data.index.freq is None:\n",
    "        station_data = station_data.resample('D').sum()\n",
    "    else:\n",
    "        station_data = station_data.resample('H').sum()\n",
    "    \n",
    "    # 线性插值填充缺失值\n",
    "    station_data = station_data.interpolate(method='linear')\n",
    "    \n",
    "    # 提取要预测的目标列\n",
    "    ts_data = station_data[[target_col]].copy()\n",
    "    \n",
    "    # 添加时间特征\n",
    "    ts_data['hour'] = ts_data.index.hour\n",
    "    ts_data['day'] = ts_data.index.day\n",
    "    ts_data['month'] = ts_data.index.month\n",
    "    ts_data['year'] = ts_data.index.year\n",
    "    ts_data['dayofweek'] = ts_data.index.dayofweek\n",
    "    ts_data['is_weekend'] = (ts_data.index.dayofweek >= 5).astype(int)\n",
    "    \n",
    "    return ts_data\n",
    "\n",
    "# 3. 构建Prophet模型\n",
    "def build_prophet_model(data, target_col='TOTAL_FLOW', test_size=0.1):\n",
    "    \"\"\"\n",
    "    构建Prophet模型用于预测趋势和季节性成分\n",
    "    \"\"\"\n",
    "    # 准备Prophet所需的数据格式\n",
    "    prophet_data = data.reset_index()\n",
    "    prophet_data = prophet_data.rename(columns={'DATETIME': 'ds', target_col: 'y'})\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    train_size = int(len(prophet_data) * (1 - test_size))\n",
    "    train_data = prophet_data.iloc[:train_size].copy()\n",
    "    test_data = prophet_data.iloc[train_size:].copy()\n",
    "    \n",
    "    # 创建并训练Prophet模型\n",
    "    model = Prophet(\n",
    "        changepoint_prior_scale=0.05,  # 控制趋势变化的灵活性\n",
    "        seasonality_prior_scale=10,    # 控制季节性强度\n",
    "        seasonality_mode='additive',   # 加法季节性\n",
    "        daily_seasonality=True,        # 启用日季节性\n",
    "        weekly_seasonality=True,       # 启用周季节性\n",
    "        yearly_seasonality=True        # 启用年季节性\n",
    "    )\n",
    "    \n",
    "    # 添加美国假日\n",
    "    model.add_country_holidays(country_name='US')\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(train_data)\n",
    "    \n",
    "    # 预测整个数据集\n",
    "    future = model.make_future_dataframe(periods=len(test_data), freq='D')\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # 提取训练集的拟合结果和残差\n",
    "    train_forecast = forecast.iloc[:train_size].copy()\n",
    "    train_data['yhat'] = train_forecast['yhat'].values\n",
    "    train_data['residual'] = train_data['y'] - train_data['yhat']\n",
    "    \n",
    "    # 提取测试集的预测结果\n",
    "    test_forecast = forecast.iloc[train_size:].copy()\n",
    "    test_data['yhat'] = test_forecast['yhat'].values\n",
    "    \n",
    "    # 合并数据\n",
    "    full_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "    \n",
    "    # 返回模型、预测结果和原始数据（包含残差）\n",
    "    return model, forecast, full_data\n",
    "\n",
    "# 4. 构建LSTM模型用于预测残差\n",
    "def create_lstm_dataset(data, lookback=7):\n",
    "    \"\"\"\n",
    "    为LSTM准备时间序列数据（滑动窗口）\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(data)):\n",
    "        X.append(data[i-lookback:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_lstm_model(data, residual_col='residual', test_size=0.1, lookback=7):\n",
    "    \"\"\"\n",
    "    构建LSTM模型用于预测残差序列\n",
    "    \"\"\"\n",
    "    # 确保数据是按时间排序的\n",
    "    data = data.sort_values('ds')\n",
    "    \n",
    "    # 获取残差序列\n",
    "    residuals = data[residual_col].values.reshape(-1, 1)\n",
    "    \n",
    "    # 数据归一化\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    residuals_scaled = scaler.fit_transform(residuals)\n",
    "    \n",
    "    # 创建LSTM数据集\n",
    "    X, y = create_lstm_dataset(residuals_scaled, lookback=lookback)\n",
    "    \n",
    "    # 划分训练集和验证集\n",
    "    train_size = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    # 构建LSTM模型\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(lookback, 1), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # 设置早停机制以防止过拟合\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # 训练模型\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 预测\n",
    "    train_predict = model.predict(X_train)\n",
    "    test_predict = model.predict(X_test)\n",
    "    \n",
    "    # 反向转换回原始尺度\n",
    "    train_predict = scaler.inverse_transform(train_predict)\n",
    "    test_predict = scaler.inverse_transform(test_predict)\n",
    "    y_train_inv = scaler.inverse_transform(y_train)\n",
    "    y_test_inv = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    # 准备结果\n",
    "    lstm_results = {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'train_predict': train_predict,\n",
    "        'test_predict': test_predict,\n",
    "        'y_train': y_train_inv,\n",
    "        'y_test': y_test_inv,\n",
    "        'lookback': lookback,\n",
    "        'history': history\n",
    "    }\n",
    "    \n",
    "    return lstm_results\n",
    "\n",
    "# 5. 混合Prophet-LSTM模型\n",
    "def hybrid_forecast(prophet_forecast, lstm_results, prophet_data, test_size=0.1, weights=None):\n",
    "    \"\"\"\n",
    "    融合Prophet和LSTM预测结果\n",
    "    weights: 如果提供，使用固定权重；否则，根据验证集表现确定最优权重\n",
    "    \"\"\"\n",
    "    # 准备Prophet预测和实际值\n",
    "    train_size = int(len(prophet_data) * (1 - test_size))\n",
    "    \n",
    "    # 分离训练集和测试集\n",
    "    train_data = prophet_data.iloc[:train_size].copy()\n",
    "    test_data = prophet_data.iloc[train_size:].copy()\n",
    "    \n",
    "    # 获取LSTM预测的残差\n",
    "    lstm_train_residuals = lstm_results['train_predict'].flatten()\n",
    "    lstm_test_residuals = lstm_results['test_predict'].flatten()\n",
    "    \n",
    "    # 对齐索引（由于LSTM需要lookback，会减少部分样本）\n",
    "    lookback = lstm_results['lookback']\n",
    "    \n",
    "    # Prophet训练集预测\n",
    "    prophet_train_preds = train_data['yhat'].values[lookback:]\n",
    "    \n",
    "    # Prophet测试集预测\n",
    "    prophet_test_preds = test_data['yhat'].values\n",
    "    \n",
    "    # 实际值\n",
    "    train_actual = train_data['y'].values[lookback:]\n",
    "    test_actual = test_data['y'].values\n",
    "    \n",
    "    # 确定最佳权重\n",
    "    if weights is None:\n",
    "        best_weight = optimize_weights(prophet_train_preds, lstm_train_residuals, train_actual)\n",
    "    else:\n",
    "        best_weight = weights\n",
    "    \n",
    "    # 融合预测结果\n",
    "    hybrid_train_preds = prophet_train_preds * best_weight + (prophet_train_preds + lstm_train_residuals) * (1 - best_weight)\n",
    "    hybrid_test_preds = prophet_test_preds * best_weight + (prophet_test_preds + lstm_test_residuals) * (1 - best_weight)\n",
    "    \n",
    "    # 计算评估指标\n",
    "    prophet_train_rmse = np.sqrt(mean_squared_error(train_actual, prophet_train_preds))\n",
    "    prophet_test_rmse = np.sqrt(mean_squared_error(test_actual, prophet_test_preds))\n",
    "    \n",
    "    hybrid_train_rmse = np.sqrt(mean_squared_error(train_actual, hybrid_train_preds))\n",
    "    hybrid_test_rmse = np.sqrt(mean_squared_error(test_actual, hybrid_test_preds))\n",
    "    \n",
    "    hybrid_train_mae = mean_absolute_error(train_actual, hybrid_train_preds)\n",
    "    hybrid_test_mae = mean_absolute_error(test_actual, hybrid_test_preds)\n",
    "    \n",
    "    try:\n",
    "        hybrid_train_mape = mean_absolute_percentage_error(train_actual, hybrid_train_preds) * 100\n",
    "        hybrid_test_mape = mean_absolute_percentage_error(test_actual, hybrid_test_preds) * 100\n",
    "    except:\n",
    "        # 处理可能的除零错误\n",
    "        hybrid_train_mape = np.nan\n",
    "        hybrid_test_mape = np.nan\n",
    "    \n",
    "    # 准备结果\n",
    "    results = {\n",
    "        'prophet_train_preds': prophet_train_preds,\n",
    "        'prophet_test_preds': prophet_test_preds,\n",
    "        'lstm_train_residuals': lstm_train_residuals,\n",
    "        'lstm_test_residuals': lstm_test_residuals,\n",
    "        'hybrid_train_preds': hybrid_train_preds,\n",
    "        'hybrid_test_preds': hybrid_test_preds,\n",
    "        'train_actual': train_actual,\n",
    "        'test_actual': test_actual,\n",
    "        'best_weight': best_weight,\n",
    "        'metrics': {\n",
    "            'prophet_train_rmse': prophet_train_rmse,\n",
    "            'prophet_test_rmse': prophet_test_rmse,\n",
    "            'hybrid_train_rmse': hybrid_train_rmse,\n",
    "            'hybrid_test_rmse': hybrid_test_rmse,\n",
    "            'hybrid_train_mae': hybrid_train_mae,\n",
    "            'hybrid_test_mae': hybrid_test_mae,\n",
    "            'hybrid_train_mape': hybrid_train_mape,\n",
    "            'hybrid_test_mape': hybrid_test_mape\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def optimize_weights(prophet_preds, lstm_residuals, actual, step=0.1):\n",
    "    \"\"\"\n",
    "    优化Prophet和LSTM混合权重\n",
    "    \"\"\"\n",
    "    best_rmse = float('inf')\n",
    "    best_weight = 0.5  # 默认权重\n",
    "    \n",
    "    # 尝试不同的权重\n",
    "    for weight in np.arange(0, 1.01, step):\n",
    "        # 计算混合预测\n",
    "        hybrid_preds = prophet_preds * weight + (prophet_preds + lstm_residuals) * (1 - weight)\n",
    "        \n",
    "        # 计算RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(actual, hybrid_preds))\n",
    "        \n",
    "        # 更新最佳权重\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_weight = weight\n",
    "    \n",
    "    return best_weight\n",
    "\n",
    "# 6. 可视化函数\n",
    "def plot_prophet_components(prophet_model, forecast, station_name, output_dir=None):\n",
    "    \"\"\"\n",
    "    绘制Prophet模型的分解组件\n",
    "    \"\"\"\n",
    "    # Matplotlib静态图常规版本\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    prophet_model.plot_components(forecast)\n",
    "    plt.tight_layout()\n",
    "    if output_dir:\n",
    "        plt.savefig(os.path.join(output_dir, f\"{station_name}_prophet_components.png\"), dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotly交互装逼版\n",
    "    fig = make_subplots(\n",
    "        rows=4, cols=1,\n",
    "        subplot_titles=('Trend', 'Week seasonality', 'Annual seasonality', 'Day seasonality'),\n",
    "        vertical_spacing=0.1,\n",
    "        shared_xaxes=False\n",
    "    )\n",
    "    \n",
    "    # 趋势图\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=forecast['ds'], y=forecast['trend'], mode='lines', name='Trend'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 周季节性\n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    weekly = forecast[['weekly']].copy()\n",
    "    weekly['day'] = forecast['ds'].dt.dayofweek\n",
    "    weekly_avg = weekly.groupby('day')['weekly'].mean().reset_index()\n",
    "    weekly_avg['day_name'] = weekly_avg['day'].map(lambda x: weekdays[x])\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(x=weekly_avg['day_name'], y=weekly_avg['weekly'], name='Week seasonality', marker_color='indianred'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 年季节性\n",
    "    if 'yearly' in forecast.columns:\n",
    "        yearly = forecast[['ds', 'yearly']].copy()\n",
    "        yearly['month'] = yearly['ds'].dt.month\n",
    "        yearly_avg = yearly.groupby('month')['yearly'].mean().reset_index()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=yearly_avg['month'], y=yearly_avg['yearly'], mode='lines+markers', name='Annual Seasonality', line=dict(color='forestgreen')),\n",
    "            row=3, col=1\n",
    "        )\n",
    "        fig.update_xaxes(title_text='Months', tickvals=list(range(1, 13)), row=3, col=1)\n",
    "    else:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=[0], y=[0], mode='markers', name='Annual seasonality is not in use', marker=dict(color='gray')),\n",
    "            row=3, col=1\n",
    "        )\n",
    "    \n",
    "    # 日季节性\n",
    "    if 'daily' in forecast.columns:\n",
    "        daily = forecast[['ds', 'daily']].copy()\n",
    "        daily['hour'] = daily['ds'].dt.hour\n",
    "        daily_avg = daily.groupby('hour')['daily'].mean().reset_index()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=daily_avg['hour'], y=daily_avg['daily'], mode='lines+markers', name='Day seasonality', line=dict(color='royalblue')),\n",
    "            row=4, col=1\n",
    "        )\n",
    "        fig.update_xaxes(title_text='小时', tickvals=list(range(0, 24)), row=4, col=1)\n",
    "    else:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=[0], y=[0], mode='markers', name='Daily seasonality is not in use', marker=dict(color='gray')),\n",
    "            row=4, col=1\n",
    "        )\n",
    "        \n",
    "    fig.update_layout(\n",
    "        height=900,\n",
    "        title_text=f\"{station_name} - Prophet模型分解组件\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    if output_dir:\n",
    "        fig.write_html(os.path.join(output_dir, f\"{station_name}_prophet_components.html\"))\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def plot_hybrid_results(hybrid_results, station_name, output_dir=None, title=None):\n",
    "    \"\"\"\n",
    "    绘制混合模型的预测结果对比\n",
    "    \"\"\"\n",
    "    if title is None:\n",
    "        title = f\"{station_name} Prediction results of the prophet-LSTM model\"\n",
    "        \n",
    "    train_actual = hybrid_results['train_actual']\n",
    "    test_actual = hybrid_results['test_actual']\n",
    "    prophet_train = hybrid_results['prophet_train_preds']\n",
    "    prophet_test = hybrid_results['prophet_test_preds']\n",
    "    hybrid_train = hybrid_results['hybrid_train_preds']\n",
    "    hybrid_test = hybrid_results['hybrid_test_preds']\n",
    "    \n",
    "    # Matplotlib静态图版本\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # 训练集\n",
    "    train_indices = np.arange(len(train_actual))\n",
    "    plt.plot(train_indices, train_actual, label='Actual value (training set)', color='blue')\n",
    "    plt.plot(train_indices, prophet_train, label='Prophet Prediction (Training Set)', color='green', linestyle='--')\n",
    "    plt.plot(train_indices, hybrid_train, label='Prophrt-LSTM model Prediction (Training set)', color='red', linestyle='-.')\n",
    "    \n",
    "    # 测试集\n",
    "    test_indices = np.arange(len(train_actual), len(train_actual) + len(test_actual))\n",
    "    plt.plot(test_indices, test_actual, label='Actual value (test set)', color='blue')\n",
    "    plt.plot(test_indices, prophet_test, label='Prophet Prediction (Test Set)', color='green', linestyle='--')\n",
    "    plt.plot(test_indices, hybrid_test, label='Prophet-LSTM model prediction(Test set)', color='red', linestyle='-.')\n",
    "    \n",
    "    # 添加分隔线\n",
    "    plt.axvline(x=len(train_actual), color='gray', linestyle='-')\n",
    "    plt.text(len(train_actual) + 1, plt.ylim()[1] * 0.9, '测试集开始', fontsize=12)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('Ridership')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    if output_dir:\n",
    "        plt.savefig(os.path.join(output_dir, f\"{station_name}_hybrid_results.png\"), dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotly交互装逼版\n",
    "    # 创建日期索引\n",
    "    train_dates = pd.date_range(end=pd.Timestamp.today() - pd.Timedelta(days=len(test_actual)), periods=len(train_actual), freq='D')\n",
    "    test_dates = pd.date_range(start=train_dates[-1] + pd.Timedelta(days=1), periods=len(test_actual), freq='D')\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # 添加实际值\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(train_dates) + list(test_dates),\n",
    "        y=list(train_actual) + list(test_actual),\n",
    "        mode='lines',\n",
    "        name='Actual Ridership',\n",
    "        line=dict(color='royalblue', width=2)\n",
    "    ))\n",
    "    \n",
    "    # 添加Prophet预测值\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(train_dates) + list(test_dates),\n",
    "        y=list(prophet_train) + list(prophet_test),\n",
    "        mode='lines',\n",
    "        name='Prophet Prediction',\n",
    "        line=dict(color='forestgreen', width=1.5, dash='dash')\n",
    "    ))\n",
    "    \n",
    "    # 添加混合模型预测值\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(train_dates) + list(test_dates),\n",
    "        y=list(hybrid_train) + list(hybrid_test),\n",
    "        mode='lines',\n",
    "        name='Prophet-LSTM model Prediction',\n",
    "        line=dict(color='firebrick', width=1.5)\n",
    "    ))\n",
    "    \n",
    "    # 添加训练集/测试集分隔线\n",
    "    fig.add_vline(\n",
    "        x=train_dates[-1], line_width=1.5, line_dash=\"dash\", line_color=\"gray\",\n",
    "        annotation_text=\"测试集开始\", \n",
    "        annotation_position=\"top right\"\n",
    "    )\n",
    "    \n",
    "    # 更新布局\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Ridership',\n",
    "        legend_title='Type of Data',\n",
    "        hovermode='x unified',\n",
    "        template='plotly_white',\n",
    "        height=600,\n",
    "        width=1200\n",
    "    )\n",
    "    \n",
    "    # 添加范围选择器\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=7, label=\"7天\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1月\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6月\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1年\", step=\"year\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\", label=\"ALL\")\n",
    "                ])\n",
    "            ),\n",
    "            rangeslider=dict(visible=True),\n",
    "            type=\"date\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if output_dir:\n",
    "        fig.write_html(os.path.join(output_dir, f\"{station_name}_hybrid_results.html\"))\n",
    "        \n",
    "    fig.show()\n",
    "\n",
    "def plot_residuals_analysis(hybrid_results, station_name, output_dir=None):\n",
    "    \"\"\"\n",
    "    绘制残差分析图\n",
    "    \"\"\"\n",
    "    # 提取残差\n",
    "    train_residuals = hybrid_results['train_actual'] - hybrid_results['hybrid_train_preds']\n",
    "    test_residuals = hybrid_results['test_actual'] - hybrid_results['hybrid_test_preds']\n",
    "    all_residuals = np.concatenate([train_residuals, test_residuals])\n",
    "    \n",
    "    # Plotly版本\n",
    "    # 1. 残差分布图\n",
    "    fig_dist = go.Figure()\n",
    "    fig_dist.add_trace(go.Histogram(\n",
    "        x=all_residuals,\n",
    "        nbinsx=50,\n",
    "        opacity=0.7,\n",
    "        marker_color='royalblue',\n",
    "        name='Residual Distribution'\n",
    "    ))\n",
    "    \n",
    "    # 添加正态分布拟合线\n",
    "    x_range = np.linspace(min(all_residuals), max(all_residuals), 100)\n",
    "    mean = np.mean(all_residuals)\n",
    "    std = np.std(all_residuals)\n",
    "    y_norm = np.exp(-(x_range - mean)**2 / (2 * std**2)) / (std * np.sqrt(2 * np.pi))\n",
    "    y_norm = y_norm * len(all_residuals) * (max(all_residuals) - min(all_residuals)) / 50  # 缩放到直方图高度\n",
    "    \n",
    "    fig_dist.add_trace(go.Scatter(\n",
    "        x=x_range,\n",
    "        y=y_norm,\n",
    "        mode='lines',\n",
    "        name='Normal Distribution Fitting',\n",
    "        line=dict(color='firebrick', width=2)\n",
    "    ))\n",
    "    \n",
    "    fig_dist.update_layout(\n",
    "        title=f'{station_name} - 残差分布分析',\n",
    "        xaxis_title='Residual',\n",
    "        yaxis_title='Frequency',\n",
    "        template='plotly_white',\n",
    "        height=500,\n",
    "        width=900\n",
    "    )\n",
    "    \n",
    "    if output_dir:\n",
    "        fig_dist.write_html(os.path.join(output_dir, f\"{station_name}_residual_distribution.html\"))\n",
    "    \n",
    "    fig_dist.show()\n",
    "    \n",
    "    # 2. 残差时序图\n",
    "    # 创建日期索引\n",
    "    train_dates = pd.date_range(end=pd.Timestamp.today() - pd.Timedelta(days=len(test_residuals)), periods=len(train_residuals), freq='D')\n",
    "    test_dates = pd.date_range(start=train_dates[-1] + pd.Timedelta(days=1), periods=len(test_residuals), freq='D')\n",
    "    \n",
    "    fig_ts = go.Figure()\n",
    "    \n",
    "    # 添加训练集残差\n",
    "    fig_ts.add_trace(go.Scatter(\n",
    "        x=train_dates,\n",
    "        y=train_residuals,\n",
    "        mode='lines',\n",
    "        name='Residual of the training set',\n",
    "        line=dict(color='royalblue', width=1)\n",
    "    ))\n",
    "    \n",
    "    # 添加测试集残差\n",
    "    fig_ts.add_trace(go.Scatter(\n",
    "        x=test_dates,\n",
    "        y=test_residuals,\n",
    "        mode='lines',\n",
    "        name='Residual of the test set',\n",
    "        line=dict(color='firebrick', width=1)\n",
    "    ))\n",
    "    \n",
    "    # 添加零线\n",
    "    fig_ts.add_hline(\n",
    "        y=0, line_width=1, line_dash=\"solid\", line_color=\"black\"\n",
    "    )\n",
    "    \n",
    "    # 训练集/测试集分隔线\n",
    "    fig_ts.add_vline(\n",
    "        x=train_dates[-1], line_width=1, line_dash=\"dash\", line_color=\"gray\",\n",
    "        annotation_text=\"测试集开始\", \n",
    "        annotation_position=\"top right\"\n",
    "    )\n",
    "    \n",
    "    fig_ts.update_layout(\n",
    "        title=f'{station_name} - 残差时序分析',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Residual',\n",
    "        legend_title='Type of Data',\n",
    "        hovermode='x unified',\n",
    "        template='plotly_white',\n",
    "        height=500,\n",
    "        width=900,\n",
    "        xaxis=dict(\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=7, label=\"7d\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1month\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=3, label=\"3months\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\", label=\"All\")\n",
    "                ])\n",
    "            ),\n",
    "            rangeslider=dict(visible=True),\n",
    "            type=\"date\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if output_dir:\n",
    "        fig_ts.write_html(os.path.join(output_dir, f\"{station_name}_residual_timeseries.html\"))\n",
    "    \n",
    "    fig_ts.show()\n",
    "\n",
    "def plot_station_traffic_heatmap(station_data, station_name, output_dir=None):\n",
    "    \"\"\"\n",
    "    绘制车站客流量热力图（按小时和星期几）\n",
    "    \"\"\"\n",
    "    # 确保有日期索引和必要的列\n",
    "    if not isinstance(station_data.index, pd.DatetimeIndex):\n",
    "        print(\"数据索引不是日期时间格式，无法创建热力图。\")\n",
    "        return\n",
    "    \n",
    "    # 准备热力图数据\n",
    "    df_heatmap = station_data.copy()\n",
    "    df_heatmap['hour'] = df_heatmap.index.hour\n",
    "    df_heatmap['dayofweek'] = df_heatmap.index.dayofweek\n",
    "    \n",
    "    # 按小时和星期几聚合\n",
    "    pivot_table = df_heatmap.pivot_table(\n",
    "        values='TOTAL_FLOW', \n",
    "        index='hour',\n",
    "        columns='dayofweek',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    # 重命名列以显示星期几\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thusrday', 'Friday', 'Saturday', 'Sunday']\n",
    "    pivot_table.columns = days\n",
    "    \n",
    "    # Plotly热力图\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=pivot_table.values,\n",
    "        x=pivot_table.columns,\n",
    "        y=pivot_table.index,\n",
    "        colorscale='Viridis',\n",
    "        hoverongaps=False,\n",
    "        colorbar=dict(title='Average Ridership')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'{station_name} - 客流量热力图 (按小时和星期)',\n",
    "        xaxis_title='Week',\n",
    "        yaxis_title='Hour',\n",
    "        height=600,\n",
    "        width=900,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    if output_dir:\n",
    "        fig.write_html(os.path.join(output_dir, f\"{station_name}_traffic_heatmap.html\"))\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def plot_monthly_trend(station_data, station_name, output_dir=None):\n",
    "    \"\"\"\n",
    "    绘制月度客流量趋势图\n",
    "    \"\"\"\n",
    "    # 按月聚合\n",
    "    monthly_data = station_data['TOTAL_FLOW'].resample('M').sum()\n",
    "    \n",
    "    # Plotly图表\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=monthly_data.index,\n",
    "        y=monthly_data.values,\n",
    "        mode='lines+markers',\n",
    "        name='月度总客流量',\n",
    "        line=dict(color='royalblue', width=2),\n",
    "        marker=dict(size=8)\n",
    "    ))\n",
    "    \n",
    "    # 添加趋势线（简单移动平均）\n",
    "    rolling_avg = monthly_data.rolling(window=3).mean()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=rolling_avg.index,\n",
    "        y=rolling_avg.values,\n",
    "        mode='lines',\n",
    "        name='3 Months MA',\n",
    "        line=dict(color='firebrick', width=2, dash='dash')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'{station_name} - 月度客流量趋势',\n",
    "        xaxis_title='MOnth',\n",
    "        yaxis_title='Total Ridership',\n",
    "        legend_title='指标',\n",
    "        hovermode='x unified',\n",
    "        template='plotly_white',\n",
    "        height=500,\n",
    "        width=900\n",
    "    )\n",
    "    \n",
    "    if output_dir:\n",
    "        fig.write_html(os.path.join(output_dir, f\"{station_name}_monthly_trend.html\"))\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def print_metrics(hybrid_results):\n",
    "    \"\"\"\n",
    "    打印评估指标\n",
    "    \"\"\"\n",
    "    metrics = hybrid_results['metrics']\n",
    "    print('\\n预测评估指标:')\n",
    "    print('-' * 50)\n",
    "    print(f\"Prophet训练集RMSE: {metrics['prophet_train_rmse']:.2f}\")\n",
    "    print(f\"Prophet测试集RMSE: {metrics['prophet_test_rmse']:.2f}\")\n",
    "    print(f\"混合模型训练集RMSE: {metrics['hybrid_train_rmse']:.2f}\")\n",
    "    print(f\"混合模型测试集RMSE: {metrics['hybrid_test_rmse']:.2f}\")\n",
    "    print(f\"混合模型训练集MAE: {metrics['hybrid_train_mae']:.2f}\")\n",
    "    print(f\"混合模型测试集MAE: {metrics['hybrid_test_mae']:.2f}\")\n",
    "    print(f\"混合模型训练集MAPE: {metrics['hybrid_train_mape']:.2f}%\")\n",
    "    print(f\"混合模型测试集MAPE: {metrics['hybrid_test_mape']:.2f}%\")\n",
    "    print(f\"最佳混合权重: {hybrid_results['best_weight']:.2f}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "# 7. 主函数\n",
    "def main():\n",
    "    \"\"\"\n",
    "    主函数，运行全部流程\n",
    "    \"\"\"\n",
    "    # 1. 加载数据\n",
    "    data_files = glob.glob(os.path.join(os.path.expanduser(\"~/Desktop\"), \"turnstile-usage-data-*.csv\"))\n",
    "    \n",
    "    if not data_files:\n",
    "        print(\"未找到数据文件，请确认数据文件位于桌面上。\")\n",
    "        return\n",
    "    \n",
    "    print(f\"找到以下数据文件: {[os.path.basename(f) for f in data_files]}\")\n",
    "    \n",
    "    # 加载数据\n",
    "    print(\"正在加载数据...\")\n",
    "    df = load_turnstile_data(data_files)\n",
    "    print(f\"加载完成，共 {len(df)} 条记录。\")\n",
    "    \n",
    "    # 2. 数据预处理\n",
    "    print(\"正在预处理数据...\")\n",
    "    df_processed = preprocess_data(df)\n",
    "    print(f\"预处理完成，剩余 {len(df_processed)} 条有效记录。\")\n",
    "    \n",
    "    # 3. 聚合数据（按天）\n",
    "    print(\"正在聚合数据...\")\n",
    "    df_daily = aggregate_by_station(df_processed, time_interval='D')\n",
    "    \n",
    "    # 4. 选择一个繁忙的车站进行建模\n",
    "    # 计算每个车站的总流量\n",
    "    station_totals = df_daily.groupby('STATION')['TOTAL_FLOW'].sum().sort_values(ascending=False)\n",
    "    top_stations = station_totals.head(10)\n",
    "    \n",
    "    print(\"\\n流量最大的10个车站:\")\n",
    "    for i, (station, total) in enumerate(top_stations.items(), 1):\n",
    "        print(f\"{i}. {station}: {total:,}\")\n",
    "    \n",
    "    # 选择流量最大的车站\n",
    "    target_station = top_stations.index[0]\n",
    "    print(f\"\\n选择 {target_station} 用于建模...\")\n",
    "    \n",
    "    # 5. 准备特定车站数据\n",
    "    station_data = prepare_station_data(df_daily, target_station)\n",
    "    print(f\"准备了 {len(station_data)} 天的数据用于模型训练和测试。\")\n",
    "    \n",
    "    # 查看基本统计\n",
    "    print(\"\\n数据统计摘要:\")\n",
    "    print(station_data['TOTAL_FLOW'].describe())\n",
    "    \n",
    "    # 6. 构建Prophet模型\n",
    "    print(\"\\n正在构建Prophet模型...\")\n",
    "    prophet_model, prophet_forecast, prophet_data = build_prophet_model(station_data, test_size=0.2)\n",
    "    \n",
    "    # 7. 构建LSTM残差模型\n",
    "    print(\"正在构建LSTM残差模型...\")\n",
    "    lstm_results = build_lstm_model(prophet_data, test_size=0.2, lookback=7)\n",
    "    \n",
    "    # 8. 混合模型预测\n",
    "    print(\"正在融合模型结果...\")\n",
    "    hybrid_results = hybrid_forecast(prophet_forecast, lstm_results, prophet_data, test_size=0.2)\n",
    "    \n",
    "    # 9. 显示结果\n",
    "    print_metrics(hybrid_results)\n",
    "    \n",
    "    # 10. 可视化\n",
    "    print(\"\\n生成可视化结果...\")\n",
    "    plot_prophet_components(prophet_model, prophet_forecast)\n",
    "    plot_hybrid_results(hybrid_results, title=f\"{target_station} 车站客流量预测\")\n",
    "    \n",
    "    print(\"\\n建模完成！\")\n",
    "    \n",
    "    return prophet_model, prophet_forecast, lstm_results, hybrid_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba9716e-06d8-4347-b767-7a6ce3c64d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f93776-f0e9-41b0-85a4-2d9c218ad403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56013b6-e660-4694-986a-86cf227839e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
